{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/fundamental-os-page-cache/",
    "result": {"data":{"cur":{"id":"174ae09d-f54c-5e52-9b16-a17b05c7b0c0","html":"<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#step-11-%EA%B3%BC%EA%B1%B0%EC%9D%98-%EC%9D%B4%EC%95%BC%EA%B8%B0\">STEP 1.1 과거의 이야기</a></p>\n</li>\n<li>\n<p><a href=\"#step-12-%EB%B2%88%EC%99%B8-nvme%EB%A5%BC-%EC%8A%A4%EC%99%91-%EC%98%81%EC%97%AD%EC%9C%BC%EB%A1%9C-%EC%9E%A1%EC%9C%BC%EB%A9%B4-ram%EA%B3%BC-%EC%86%8D%EB%8F%84%EA%B0%80-%EB%B9%84%EC%8A%B7%ED%95%A0%EA%B9%8C\">STEP 1.2 번외) NVMe를 스왑 영역으로 잡으면 RAM과 속도가 비슷할까?</a></p>\n</li>\n<li>\n<p><a href=\"#step-21-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C%EC%9D%98-%EC%BA%90%EC%8B%9C-%EC%98%81%EC%97%AD%EA%B3%BC-%EC%8A%A4%EC%99%80%ED%95%91\">STEP 2.1 운영체제의 캐시 영역과 스와핑</a></p>\n<ul>\n<li><a href=\"#step-211-%EC%BA%90%EC%8B%9C%EC%98%81%EC%97%AD\">STEP 2.1.1 캐시영역</a></li>\n<li><a href=\"#step-212-%EC%8A%A4%EC%99%80%ED%95%91\">STEP 2.1.2 스와핑</a></li>\n<li><a href=\"#step-213-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C%EC%9D%98-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%9E%AC%ED%95%A0%EB%8B%B9-%EB%B0%A9%EC%8B%9D\">STEP 2.1.3 운영체제의 메모리 재할당 방식</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#step-22-%EC%9E%90%EB%B0%94-%ED%8E%98%EC%9D%B4%EC%A7%80-%EC%BA%90%EC%8B%9C-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EA%B0%80%EB%B9%84%EC%A7%80-%EC%BB%AC%EB%A0%89%EC%85%98\">STEP 2.2 자바, 페이지 캐시 그리고 가비지 컬렉션</a></p>\n<ul>\n<li><a href=\"#step-221-%ED%8E%98%EC%9D%B4%EC%A7%80-%EC%BA%90%EC%8B%9C%EC%99%80-%EB%8D%94%ED%8B%B0-%ED%8E%98%EC%9D%B4%EC%A7%80-%EB%8F%99%EA%B8%B0%ED%99%94\">STEP 2.2.1 페이지 캐시와 더티 페이지 동기화</a></li>\n<li><a href=\"#step-222-%EC%9E%90%EB%B0%94-%EB%A9%94%EB%AA%A8%EB%A6%AC%EC%99%80-%EA%B0%80%EB%B9%84%EC%A7%80-%EC%BB%AC%EB%A0%89%EC%85%98\">STEP 2.2.2 자바 메모리와 가비지 컬렉션</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#step-31-%EC%B6%94%EC%8B%A0\">STEP 3.1 추신</a></p>\n</li>\n</ul>\n</div>\n<ul>\n<li>STEP 1. 서론\n<ul>\n<li>STEP 1.1 과거의 이야기</li>\n<li>STEP 1.2 번외) NVMe를 스왑 영역으로 잡으면 RAM과 속도가 비슷할까?</li>\n</ul>\n</li>\n<li>STEP 2. 본론\n<ul>\n<li>STEP 2.1 운영체제의 캐시 영역과 스와핑\n<ul>\n<li>STEP 2.1.1 캐시영역</li>\n<li>STEP 2.1.2 스와핑</li>\n<li>STEP 2.1.3 운영체제의 메모리 재할당 방식</li>\n</ul>\n</li>\n<li>STEP 2.2 자바, 페이지 캐시 그리고 가비지 컬렉션\n<ul>\n<li>STEP 2.2.1 페이지 캐시와 더티 페이지 동기화</li>\n<li>STEP 2.2.2 자바 메모리와 가비지 컬렉션</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>STEP 3. 결론</li>\n<li>STEP 4. 참고자료</li>\n</ul>\n<h1 id=\"step-1-서론\" style=\"position:relative;\"><a href=\"#step-1-%EC%84%9C%EB%A1%A0\" aria-label=\"step 1 서론 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 1. 서론</h1>\n<p>카프카 핵심가이드를 읽으면서, 챕터 1의 운영체제 튜닝하기(p.40) 부분을 보면서 궁금한 점이 생겨났다.</p>\n<blockquote>\n<p>대부분의 어플리케이션, 특히 처리량이 중요한 어플리케이션에서는 (거의) 어떻게 해서든 스와핑을 막는 것이 최선이다.</p>\n<p>-카프카 핵심가이드, p.40-</p>\n</blockquote>\n<p>당연히, 운영체제 레벨에서 지원하는 가상 메모리는 실제 메모리가 아니고 디스크를 임시로 메모리처럼 사용하는 방식이기에 이 부분은 <strong>처리량이 중요한</strong> 어플리케이션이면 사용하지 않는 것이 맞다는 생각은 들었으나 정확히 왜? 라는 부분에 대해서는 궁금증이 생겼다.</p>\n<p>이 내용은 카프카 뿐만아니라 ES에도 정리가 되어있다.</p>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html\">Disable swapping - Elasticsearch Guide 8.8</a></li>\n</ul>\n<p>이 부분에 대해서 정리를 해보고자 한다.</p>\n<p>물론, 독자분들이 스왑(가상 메모리) 영역에 대한 기본적인 개념이 있다고 가정하고 서술할 내용이니 이 부분을 잘 모른다면 다른 블로그나 기타 자료를 참고해보기 바란다.</p>\n<h2 id=\"step-11-과거의-이야기\" style=\"position:relative;\"><a href=\"#step-11-%EA%B3%BC%EA%B1%B0%EC%9D%98-%EC%9D%B4%EC%95%BC%EA%B8%B0\" aria-label=\"step 11 과거의 이야기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 1.1 과거의 이야기</h2>\n<p>리눅스를 직접 설치한지가 벌써 10년 전으로 기억하는데 그때 당시만 해도, 스왑 영역에 대한 가이드로 대부분의 블로그에 아래와 같은 글들이 많이 보였다.</p>\n<blockquote>\n<p>스왑 영역은 RAM의 2배정도 크기로 할당한다.</p>\n</blockquote>\n<p>사실, 이 내용은 레드햇 공식 가이드에 있던 내용으로 인해서 구전되던 내용이 여러번 희석되서 해당 시스템의 메모리 2배를 할당한다고 내려온거지 않을까? 생각해본다.</p>\n<p>아래는 현재 RHEL 9의 스왑 영역에 대한 가이드이다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/5q8qYzf.png\">\n</p>\n<p align=\"center\">\n    <em>그림 1. <a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_storage_devices/getting-started-with-swap_managing-storage-devices\">RHEL Recommended System Swap Space</a></em>\n</p>\n<p>학생때는 스왑 메모리에 대한 이해가 없이 사용하다보니 위와 같은 가이드를 따르기 보다는 통상 2배로 설정하라해서 그대로 따랐던 기억이 있다.</p>\n<p>하지만, 요즘날과 같이 물리 메모리(RAM)이 저렴해진 환경에서 스왑이 굳이 필요할까? 이러한 생각도 들게되었다.</p>\n<p>이 부분은 서버 엔지니어분들이 많이 계신 커뮤니티인 2cpu에 많은 질답이 오고간 것을 확인할 수 있다.</p>\n<ol>\n<li><a href=\"https://www.2cpu.co.kr/QnA/477563#c_477565\">Ubuntu Swap 파티션 크기 - 2cpu</a></li>\n<li><a href=\"https://www.2cpu.co.kr/bbs/board.php?bo_table=QnA&#x26;wr_id=556001\">요즘같이 메모리 큰 환경에서 리눅스 스왑영역은 어떻게 잡으세요? - 2cpu</a></li>\n</ol>\n<p>1번은 15년도에 올라온 질문글이고, 2번은 16년도에 올라온 질문글임을 확인할 수 있다.</p>\n<p>1번 질문 글의 경우에는 김한구님께서 답변해주신 내용이 인상 깊었다.</p>\n<blockquote>\n<p>스왑 파티션이라는 것이 옛날에 물리적인 메모리가 부족하던 시절, 하드 디스크를 메모리처럼 사용하려고 만들어진 것인데 메모리가 128기가인 경우에는 부족할 것 같지 않으니 필요가 없어보인다. 그러나, 스왑을 안잡으면 경고 메시지가 뜰테니 대략 2-4기가 정도만 잡아도 충분해보인다.</p>\n</blockquote>\n<p>레드햇의 가이드와 매우 흡사해보인다.</p>\n<p>2번 질문 글의 경우에는 2가지 답변이 인상 깊었다.</p>\n<ul>\n<li>깡통이님</li>\n</ul>\n<blockquote>\n<p>스왑의 사용할 때의 장점은 2가지입니다.</p>\n<ol>\n<li>스왑이 있으면 실제 메모리 이상으로 사용했을 때 다운되지 않고, 느려지면서 동작</li>\n<li>스왑이 있으면 OS는 거의 사용하지 않는 메모리 영역을 스왑으로 내리고,  확보된 공간을 디스크 캐쉬로 돌릴 수 있다.</li>\n</ol>\n<p>스왑을 사용해서 느려지는건 싫지만, 1번의 경우때문에 스왑을 사용하게 하고 싶으면 적당히 잡고 vm.swappiness를 0 ~ 10 사이로 설정해서 최대한 물리메모리를 사용하도록 설정하면 됩니다.</p>\n</blockquote>\n<ul>\n<li>박님</li>\n</ul>\n<blockquote>\n<p>어플리케이션에 따라서도 달라집니다.\n오라클의 경우 메모리의 3배를 권장하기도하고, 특수한 경우 메모리의 내용을 덤프 받기 위해 최소 메모리 용량만큼의 스왑 공간을 요구하는 경우도 있습니다.</p>\n</blockquote>\n<p>또한, 다른 분께서는 스왑을 사용하는 이유에 최대절전모드(hibernation)을 얘기도 했는데 이 부분은 <a href=\"https://kwonnam.pe.kr/wiki/linux/ubuntu/hibernation\">Ubuntu Linux Hibernation - 권남</a> 를 참고해보자. 아마 최대절전모드가 동작할 때 스왑 영역을 활용하는 것으로 보인다.</p>\n<p>종합을 해보면 아래와 같은 결론을 내릴 수 있을 것이다.</p>\n<ul>\n<li>가용한 물리적 메모리와 어플리케이션의 사용량에 따라 스왑을 적절하게 설정할 수 있다.\n<ul>\n<li>만약, 필요가 없다 가정하면 아예 설정을 하지않을 수 있다.</li>\n</ul>\n</li>\n<li>스왑 영역을 세팅한다면 실제 RAM을 초과해도 속도는 느려지겠지만 시스템 다운은 막을 수 있다.</li>\n</ul>\n<h2 id=\"step-12-번외-nvme를-스왑-영역으로-잡으면-ram과-속도가-비슷할까\" style=\"position:relative;\"><a href=\"#step-12-%EB%B2%88%EC%99%B8-nvme%EB%A5%BC-%EC%8A%A4%EC%99%91-%EC%98%81%EC%97%AD%EC%9C%BC%EB%A1%9C-%EC%9E%A1%EC%9C%BC%EB%A9%B4-ram%EA%B3%BC-%EC%86%8D%EB%8F%84%EA%B0%80-%EB%B9%84%EC%8A%B7%ED%95%A0%EA%B9%8C\" aria-label=\"step 12 번외 nvme를 스왑 영역으로 잡으면 ram과 속도가 비슷할까 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 1.2 번외) NVMe를 스왑 영역으로 잡으면 RAM과 속도가 비슷할까?</h2>\n<p>혹자는 이런 생각을 할 수 있을 것이다.</p>\n<blockquote>\n<p>아니 NVMe를 사용하면, 거의 RAM과 속도가 비슷할테니 NVMe를 꽂은 후 이를 스왑 영역으로 잡으면 사실 상 램이 증설된 효과를 주는거 아닌가요?</p>\n</blockquote>\n<p>물론, 현재 NVMe가 DDR2의 속도를 따라잡긴했다. 하지만, DDR4는 일반적으로 20GB/s 속도이고, NVMe는 4개의 PCIe 레인을 사용하고, PCIe 3.0 기준으로 8GB/s의 속도를 가지게 된다.</p>\n<p>물론 레인(4개가 아닌 16개)을 증설하거나 PCIe 인터페이스 버전이 4.0일 경우에는 또 달라질 것이다.  하지만 이 글을 쓰는 시점에서 RAM은 DDR5 시대가 도래했고, PCIe 3.0 vs PCIe 4.0 차이에 대한 기사를 보니 성능차이가 미미하다는 점도 있다.</p>\n<p>참고 : <a href=\"http://www.weeklypost.kr/news/articleView.html?idxno=4258\">NVMe ‘PCIe 3.0 vs PCIe 4.0’ 성능? 어라, 차이없네</a></p>\n<p>그리고 위와 같은 가정도 <strong>순차적인 읽기 쓰기만 고려한 점</strong>이라는 것이다. RAM의 가장 중요한 기능 중 하나는 <strong>랜덤 액세스</strong>인데 위와 같은 가정도 <strong>랜덤 액세스로 비교를 하게되면 NVMe의 성능은 고대의 SDRAM과 비교할 수 없을 정도로 느리다.</strong></p>\n<p>그래도, HDD보다는 NVMe나 SSD를 사용하는 것이 훨씬 빠르니 적용할만하다고 생각한다.\n본디, 과거에는 SSD 수명이 매우 짧다보니 스왑으로 활용할 경우 SSD 수명이 가파르게 깎이는 문제점이 존재했으나, <a href=\"https://www.jedec.org/standards-documents/focus/flash/solid-state-drives\">JEDEC Standards</a> 를 참고하면 요즘날 SSD에는 크게 걱정할 요소는 아님으로 보인다.</p>\n<h1 id=\"step-2-본론\" style=\"position:relative;\"><a href=\"#step-2-%EB%B3%B8%EB%A1%A0\" aria-label=\"step 2 본론 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2. 본론</h1>\n<p>과거의 사례를 들어서 이야기를 해보았다. 스왑 영역을 사용하는 케이스는 아래와 같다고 정리를 할 수 있다.</p>\n<ul>\n<li>가용한 물리적 메모리와 어플리케이션의 사용량에 따라 스왑을 적절하게 설정할 수 있다.\n<ul>\n<li>만약, 필요가 없다 가정하면 아예 설정을 하지않을 수 있다.</li>\n</ul>\n</li>\n<li>스왑 영역을 세팅한다면 실제 RAM을 초과해도 속도는 느려지겠지만 시스템 다운은 막을 수 있다.</li>\n</ul>\n<p>이 두가지 결론으로 인하여 스왑은 메모리보다 속도는 느리긴 하나 가용 메모리가 없을 경우 최악의 사태는 방지할 수 있다는 점을 알 수 있다.</p>\n<p>그렇다면 이제 본격적으로 <code class=\"language-text\">vm.swappiness = 1</code>로 설정하는 이유에 대해서 설명을 해보고자한다.\n두 부분을 살펴봐야하는데 먼저 <strong>운영체제 레벨</strong>을 살펴본 후에 <strong>JVM 레벨</strong>을 살펴보는 식으로 글을 서술하고자한다.</p>\n<p>먼저, 운영체제의 캐시 관련하여 이야기가 필요하므로 이 이야기부터 진행해보고자 한다.</p>\n<h2 id=\"step-21-운영체제의-캐시-영역과-스와핑\" style=\"position:relative;\"><a href=\"#step-21-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C%EC%9D%98-%EC%BA%90%EC%8B%9C-%EC%98%81%EC%97%AD%EA%B3%BC-%EC%8A%A4%EC%99%80%ED%95%91\" aria-label=\"step 21 운영체제의 캐시 영역과 스와핑 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.1 운영체제의 캐시 영역과 스와핑</h2>\n<h3 id=\"step-211-캐시영역\" style=\"position:relative;\"><a href=\"#step-211-%EC%BA%90%EC%8B%9C%EC%98%81%EC%97%AD\" aria-label=\"step 211 캐시영역 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.1.1 캐시영역</h3>\n<p>OS 커널은 블록 디바이스(Block Devices)<sup id=\"fnref-1\"><a href=\"#fn-1\" class=\"footnote-ref\">1</a></sup> 라는 값을 통해서 디스크로 부터 데이터를 읽거나 쓴다. 하지만 당연히 이 비용은 디스크를 통하다보니 비쌀 수 밖에 없다.</p>\n<p>그래서, 커널은 메모리의 일부에 캐시영역<sup id=\"fnref-2\"><a href=\"#fn-2\" class=\"footnote-ref\">2</a></sup>을 두어 한 번 읽은 디스크의 내용을 메모리에 저장해두어 동일한 내용을 읽고자하면, 디스크에 읽기 요청을 하는 것이 아니라 캐시 영역에 값이 존재하는지 확인한 후에 가져온다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/cx5KQtU.png\">\n</p>\n<p align=\"center\">\n    <em>그림 2. 캐시영역 적재 흐름도</em>\n</p>\n<p>그림으로 보면 위와 같다고 볼 수 있다.\n실제 어플리케이션 로드 상황에서 메모리 영역 사용 현황을 보면 아래와 같이 이뤄질 것 이다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/ddqF2a0.png\">\n</p>\n<p align=\"center\">\n    <em>그림 3. 어플리케이션 로드 이후의 가용 메모리 변화</em>\n</p>\n<ol>\n<li>초기에 사용중인 메모리 영역과 가용 메모리 영역이 존재</li>\n<li>시간이 흐름에 따라 캐시영역에 데이터가 적재</li>\n<li>어플리케이션에서 사용하게 되는 영역이 점점 많아짐</li>\n<li>사용 중인 메모리 영역이 점점 커지면 캐시 영역에서 사용되던 일부를 어플리케이션이 사용하도록 변경</li>\n</ol>\n<p>이 과정 속에서 더 이상 가용 메모리가 충분하지않을 수 있는데 이때 스왑 영역이 존재하면 스왑을 사용하게 된다.</p>\n<p>그렇다면 이 스왑을 사용하는 과정은 어떻게 진행될까?</p>\n<h3 id=\"step-212-스와핑\" style=\"position:relative;\"><a href=\"#step-212-%EC%8A%A4%EC%99%80%ED%95%91\" aria-label=\"step 212 스와핑 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.1.2 스와핑</h3>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/8BNaTLn.png\">\n</p>\n<p align=\"center\">\n    <em>그림 4. 스와핑 동작 방식</em>\n</p>\n<p>OS 레벨에서의 스와핑은 위와 같이 동작을 한다.</p>\n<p>그러나, 위 그림을 보고 의아할 수도 있다.</p>\n<blockquote>\n<p>왜 프로세스가 디스크 영역에 적재되나요?</p>\n</blockquote>\n<p>그림 4는 기본적인 OS의 스와핑(Swapping)방식이다. 하지만, 가상 메모리(스왑 영역)는 <strong>프로세스 단위로 스와핑을 하는 것이 아니라 페이지 단위로 스와핑</strong>한다.</p>\n<p>그림 2에 나와있는 캐시 영역은 사실 페이지 캐시(Page Cache)<sup id=\"fnref-3\"><a href=\"#fn-3\" class=\"footnote-ref\">3</a></sup> 를 통해서 관리되는데, 이는 후술할 내용이므로 그냥 단순하게 <strong>캐시 영역에서 스왑 영역으로 이동되는 스와핑은 데이터가 디스크에 적재</strong>된다고 보면 될 것 같다.</p>\n<p>이 부분에 대해서 좀 더 깊게 알고 싶다면 아래의 링크를 참고하자.</p>\n<ul>\n<li><a href=\"https://resilient-923.tistory.com/397\">운영체제(OS) 스와핑(swapping), 가상메모리(virtual memory) 란? - 빠르고 꾸준하게</a></li>\n</ul>\n<p>그림 4에서 보는 것과 같이 스와핑에는 2가지 동작이 존재한다.</p>\n<ul>\n<li><strong>스왑-아웃(swap-out)</strong> : 메모리의 데이터 중 자주 사용되지 않은 데이터를 스왑영역으로 이동</li>\n<li><strong>스왑-인(swap-in)</strong> : 스왑으로 옮겨진 데이터를 다시 읽기 위해 데이터를 디스크에서 가져옴</li>\n</ul>\n<p>서론에서 얘기했듯이 <strong>Disk I/O 비용은 비싸다.</strong></p>\n<p>그리고 가장 큰 문제는 우리는 그림3과 같이 <strong>점점 어플리케이션이 사용량이 증가함에 따라 가용영역이 부족할 경우만 스와핑이 이뤄질 것으로 기대하지만 실제 동작은 그렇지 않다</strong>는 점이다.</p>\n<blockquote>\n<p>즉, 캐시영역이나 가용영역이 널널해도 스와핑이 발생할 수 있다.</p>\n</blockquote>\n<p>이 부분을 이해하기 위해서는 운영체제의 메모리 재할당 방식에 대해서 이해해야한다.</p>\n<h3 id=\"step-213-운영체제의-메모리-재할당-방식\" style=\"position:relative;\"><a href=\"#step-213-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C%EC%9D%98-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%9E%AC%ED%95%A0%EB%8B%B9-%EB%B0%A9%EC%8B%9D\" aria-label=\"step 213 운영체제의 메모리 재할당 방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.1.3 운영체제의 메모리 재할당 방식</h3>\n<p><strong>리눅스 커널은 메모리가 유휴 상태(idle state)로 남아있는 것을 선호하지 않는다.</strong> 이 과정을 나타낸 것이 바로 그림 3이라 보면될 것이다. 커널은 캐시 영역을 활용하는 식으로 하여 유휴 상태로 만들지 않는데, 이런식으로 운영되다보니 가용 메모리가 계속 줄게 된다. 이 때 <strong>사용하지 않는 메모리를 확인하여 필요하는 곳에 재할당 하는 것을 메모리 재할당</strong>이라 한다.</p>\n<p>그림 3의 4번째 단계를 보면 캐시 영역이 줄어들고 사용하는 메모리 영역이 증가된 것을 볼 수가 있는데 메<strong>모리 재할당 과정에서 주로 캐시 영역을 반환하고, 스와핑도 발생</strong>하게 된다.</p>\n<p><strong>즉, 가용 메모리 영역이 없다면 사용 중인 메모리 중에 반환 할 수 있는 메모리가 있는지 찾아서 반환하게 된다.</strong></p>\n<p>이때 바로 <code class=\"language-text\">vm.swappiness</code> 커널 파라미터가 사용되게 된다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/AMImeT5.png\">\n</p>\n<p align=\"center\">\n    <em>그림 5. 메모리 재할당 방식</em>\n</p>\n<p>설명했던 메모리 재할당 과정을 간략하게 표현한 것이 그림 5라고 보면 될 것이다.</p>\n<p>스와핑을 다루면서 캐시 영역이나 가용 메모리 영역이 널널한데 스와핑이 발생할 수 있다고 말했었는데 그 이유가 바로 <code class=\"language-text\">vm.swappiness</code> 값에 따라 동작 방식이 다르기 때문이다.</p>\n<p>저 커널 파라미터는 커널이 <strong>얼마나 공격적으로 메모리 영역을 스왑 영역으로 옮기느냐를 결정하는 파라미터</strong>이다. 따라서 이 값이 높아지면 캐시 영역이 여유가 있음에도 불구하고 스왑 영역을 사용하게된다. 따라서, 불필요한 스와핑이 발생하고 Disk I/O가 발생하므로 성능에 영향을 끼치는 것이다.</p>\n<p>따라서, 처리량이 높은 어플리케이션에서 <code class=\"language-text\">vm.swappiness = 1</code>로 설정하는 이유는 <strong>메모리 재할당 과정 속에서 불필요한 스와핑을 줄이고, 가능한 캐시영역을 비우고 스왑을 사용</strong>하고자 함이다.</p>\n<p>이 비율을 계산하는 공식인 Swap Tendency도 존재한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">swap_tendency = mapped_ratio/2 + distress + vm_swappiness;</code></pre></div>\n<p>이 부분은 범위를 벗어나는 부분으로 재할당 부분과 해당 파라미터 등을 자세히 알고 싶다면 아래의 링크를 참고하자.</p>\n<ul>\n<li><a href=\"https://brunch.co.kr/@alden/14\">메모리 재할당과 커널 파라미터 - 강진우님</a></li>\n</ul>\n<p>참고로 0이 아닌 1로 설정하는 이유도 위 저자분께서 친절하게 작성해두셨다.</p>\n<blockquote>\n<p>다만 1로 설정했을 때보다 훨씬 더 많은 page cache를 해제하게 됩니다.\n거의 한자리 수까지 털어 버리기 때문에 좀 더 안정적인 성능의 시스템을 원한다면 1로 세팅해서 사용하는 것도 좋을 것이라 생각됩니다.</p>\n<p>page cache를 지나치게 버리면 I/O가 높아지고 시스템의 load를 상승시킬 수 있기  때문입니다.</p>\n</blockquote>\n<p>여기서 추가적으로 페이지 캐시를 다 버리는데 왜 I/O가 높아지는지에 대해서는 JVM 레벨에서의 내용을 다루면서 서술하고자한다.</p>\n<h2 id=\"step-22-자바-페이지-캐시-그리고-가비지-컬렉션\" style=\"position:relative;\"><a href=\"#step-22-%EC%9E%90%EB%B0%94-%ED%8E%98%EC%9D%B4%EC%A7%80-%EC%BA%90%EC%8B%9C-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EA%B0%80%EB%B9%84%EC%A7%80-%EC%BB%AC%EB%A0%89%EC%85%98\" aria-label=\"step 22 자바 페이지 캐시 그리고 가비지 컬렉션 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.2 자바, 페이지 캐시 그리고 가비지 컬렉션</h2>\n<p>위에서는 운영체제 레벨에서 해당 내용을 다뤘다 물론, 저기서 끝내도 무방하지만 필자는 <code class=\"language-text\">vm.swappniess</code> 값과 JVM과는 상관관계가 있는지 궁금했다.</p>\n<p>왜냐면, Kafka와 ES 모두 JVM 위에서 동작하는 녀석들이기 때문이다.</p>\n<p>사실 이 부분도 JVM 내부를 분석한다던가 그런 내용은 아니다. 위의 기저지식을 기반으로 좀 더 세부적인 내용을 다루고, 실질적으로 어떤 영향을 끼치는지 서술할 예정이다.</p>\n<p>그 전에 우리는 먼저 페이지 캐시에 알 필요가 있다.</p>\n<h3 id=\"step-221-페이지-캐시와-더티-페이지-동기화\" style=\"position:relative;\"><a href=\"#step-221-%ED%8E%98%EC%9D%B4%EC%A7%80-%EC%BA%90%EC%8B%9C%EC%99%80-%EB%8D%94%ED%8B%B0-%ED%8E%98%EC%9D%B4%EC%A7%80-%EB%8F%99%EA%B8%B0%ED%99%94\" aria-label=\"step 221 페이지 캐시와 더티 페이지 동기화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.2.1 페이지 캐시와 더티 페이지 동기화</h3>\n<p>사실, 그림 2에서 봤던 캐시 영역과 그림 5에서 봤던 캐시 영역 모두 페이지 캐시와 동치된다고 봐도 무방하다.</p>\n<p>우리는 위에서 <strong>페이지 캐시를 통해서 한번 읽은 데이터를 적재해두고 Disk I/O를 줄이는 방식</strong>으로 운영체제가 동작함을 알게되었다.</p>\n<p>그러면 아래와 같은 궁금증이 생기는 분도 계실 것이다.</p>\n<blockquote>\n<p>만약, 페이지 캐시에 적재된 페이지 중에서 변경이 발생하면 어떻게 되나요?</p>\n</blockquote>\n<p>현재 이 글을 읽는 분들 중에서 JPA를 사용하시는 분이라면 더티 체킹(Dirty Checking)<sup id=\"fnref-4\"><a href=\"#fn-4\" class=\"footnote-ref\">4</a></sup>라는 용어를 들어보셨을 것이다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/JsiNr2f.png\">\n</p>\n<p align=\"center\">\n    <em>그림 6. 더티체킹, 자바 ORM 표준 JPA 프로그래밍, 김영한 저</em>\n</p>\n<p>간략하게 위 그림을 설명하면, 1차 캐시를 페이지 캐시라 생각하고, 기존에 적재된 내역의 상태를 스냅샷으로 볼 수 있을 것이다. 이 후 엔티티 매니저를 통해서 스냅샷을 비교하여 업데이트를 수행한다.</p>\n<p>사실 이러한 동작방식은 운영체제 레벨에서도 비슷하다. 운영체제에서는 기존 페이지 캐시에 적재된 데이터인데 변경이 이뤄진 페이지를 더티 페이지(Dirty Page)<sup id=\"fnref-5\"><a href=\"#fn-5\" class=\"footnote-ref\">5</a></sup>라 부른다.</p>\n<p>식별 방식과 처리 방식은 아래의 그림과 같다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/2IXA7Yc.png\">\n</p>\n<p align=\"center\">\n    <em>그림 7. 더티 페이지 감지 및 동기화 방식</em>\n</p>\n<ol>\n<li>A, B, C라는 데이터가 페이지 캐시에 있고, 이 값들은 디스크에 이미 적재되었다고 가정한다.</li>\n<li>페이지 캐시의 데이터 중 B -> D로 변경되었는데 이때 바로 디스크에 반영하지는 않고, 페이지 캐시에는 더티페이지를 들고있는다.</li>\n<li>특정 조건이 채워졌을 경우에 더티페이지를 디스크에 반영한다.</li>\n</ol>\n<p>위의 방식으로 처리된다고 볼 수 있다.\n여기서 페이지 캐시에서 발생된 <strong>더티페이지를 디스크에 쓰는 행위를 더티 페이지 동기화</strong>라 한다.</p>\n<p>그러면 우리는 아래와 같은 가정을 가질 수 있다.</p>\n<ul>\n<li>만약, 동기화 특정 조건을 매우 짧게 가져간다면? -> 더티페이지 생성마다 빈번하게 Disk I/O 발생</li>\n<li>만약, 동기화 특정 조건을 매우 길게 가져간다면? -> 더티페이지가 페이지캐시에 적재되는데 서버다운 시 이 데이터들은 모두 휘발</li>\n</ul>\n<p>역시 <strong>은총알은 없다.(No Silver Bullet)</strong> 하지만 우리는 처리량이 높은 JVM 어플리케이션을 기준으로 설명하고 있다보니 Disk I/O를 줄이는게 좀 더 초점이 될 수 있을 것이다.</p>\n<p>동기화의 발생 횟수 등 조건을 제어하는 커널 파라미터는 아래와 같다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">vm.dirty_backgroud_ratio \nvm.dirty_ratio \n... etc ...</code></pre></div>\n<p>이 부분에 대해서 좀 더 깊게 보고 싶으면 아래의 링크를 참고해보자.</p>\n<ul>\n<li><a href=\"https://brunch.co.kr/@alden/32\">dirty page 동기화 #1 - 강진우님</a></li>\n</ul>\n<h3 id=\"step-222-자바-메모리와-가비지-컬렉션\" style=\"position:relative;\"><a href=\"#step-222-%EC%9E%90%EB%B0%94-%EB%A9%94%EB%AA%A8%EB%A6%AC%EC%99%80-%EA%B0%80%EB%B9%84%EC%A7%80-%EC%BB%AC%EB%A0%89%EC%85%98\" aria-label=\"step 222 자바 메모리와 가비지 컬렉션 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.2.2 자바 메모리와 가비지 컬렉션</h3>\n<p>사실 이전의 내용들을 이 내용을 위한 빌드업이라고 볼 수 있다. 이제는 Kafka와 ES의 사례를 들어서 위의 내용들을 종합하고자 한다.</p>\n<p>우선, 자바 개발자면 이런 생각을 갖을 수 있다.</p>\n<blockquote>\n<p>그러면 스왑이든 페이지 캐시든 사용하기 번거로우니 자바에서 인-메모리로 관리하면 안되나요? 어차피 GC가 알아서 해주지 않나요? ㄹㅇㅋㅋ</p>\n</blockquote>\n<p>그러나, Kafka와 ES 모두 운영체제의 페이지 캐시를 활용하는데 도대체 그 이유가 무엇일까?\n이 해답은 <a href=\"https://docs.confluent.io/kafka/design/file-system-constant-time.html#ak-and-the-jvm\">Kafka 공식 문서</a>에 나와있다.</p>\n<blockquote>\n<p>Kafka is built on top of the JVM, and Java memory usage has the following characteristics:</p>\n<ol>\n<li>The memory overhead of objects is very high, often doubling the size of the data stored (or worse).</li>\n<li>Java garbage collection becomes increasingly slow as the in-heap data increases.</li>\n</ol>\n</blockquote>\n<p>즉, 위 2가지 특성때문에 자바 메모리로 관리하는 캐시보다 운영체제의 페이지 캐시를 사용하게 디자인되었다고 보면된다. 그리고 이러한 디자인의 가장 큰 장점은 바로 <strong>GC의 패널티</strong>를 줄일 수 있다는 점이다.</p>\n<p>어찌됐든 STW(Stop-the-world)는 GC하는 순간에 발생한다. 만약, 대량의 데이터가 메모리에 올라가진 상태에서 GC가 발생한다면? 그게 Full-GC라면? STW로 어플리케이션이 멈추는 시간은 매우 길어질 것이다.</p>\n<p>다른 장점으로는 어플리케이션 재시작 상황을 가정해보자 우리가 만약 캐시를 자바 메모리로 관리하고 있었다면 재시작하는 순간 캐시들이 전부 휘발될테고 이 캐시를 웜업하기 위해서 다시 상당한 시간이 소요될 것이다.</p>\n<p>하지만, 운영체제의 페이지 캐시로 관리하면 어플리케이션의 동작유무와 별개로 캐시는 존재할 것이므로 다시 웜업하는 비용이 단축될 것이다.</p>\n<p>이것과 관련된 재미난 이슈를 아래의 링크에서 확인할 수 있다.</p>\n<ul>\n<li><a href=\"https://access.redhat.com/solutions/2685771\">Java process takes a long time with -XX:+AlwaysPreTouch - Red Hat Customer Portal</a></li>\n</ul>\n<p>간단하게 설명하면 <code class=\"language-text\">-XX:+AlwaysPreTouch</code> 옵션은 Heap 사이즈가 큰 경우에 공간을 0으로 채워 초기화하는데 부팅 속도는 느려지지만 실행시 속도는 빨라진다는 이점이 있다. 즉, <strong>웜업 비용이 단축</strong>되는 명령어라고 보면될 것같다.</p>\n<p>해당 옵션을 사용하면 Xmx 설정한 힙사이즈(최대 힙사이즈)를 모두 0으로 터치한다. 이 케이스에서 원래 우리가 그림 3에서 봤던 거처럼 점진적으로 페이지 캐시가 할당되는게 어플리케이션 시작점부터 운영체제에 페이지를 요청한다.</p>\n<p>그러면 가용 메모리 영역에서 페이지를 요청하기 위해서 메모리 재할당 과정이 이뤄질 것이다.</p>\n<p>그 뒤를 생각해보자. 운영체제에 메모리를 요청해서 페이지가 생겼는데 동작과정 속에서 이미 페이지가 생겼으니 데이터가 변경될때마다 더티페이지가 생길 것이다.</p>\n<p>자 이때 가용 메모리가 부족하여 재할당 과정이 발생한다고 가정해보자. 그러면 이미 많은 양의 페이지 캐시가 생성되어있으므로 그만큼 재할당을 하는 과정이 느려질 것이고, 더티페이지 커널 파라미터도 별도 튜닝을 안했다면 Disk I/O도 많이 발생할 것이다.</p>\n<p>해당 이슈는 위와 같은 이유때문에 느려진 것이 않을까? 추론할 수 있을 것이다.</p>\n<p>자 이제, JVM 상에서 동작하는 어플리케이션들 중에서 처리량이 높아야하는 요구사항을 지닌 것들은 운영체제의 페이지 캐시를 사용하는 것을 이해할 수 있었다. 이유는 자바 메모리의 특성과 연관이 되어있었다.</p>\n<p>그러면, 왜 스왑은 쓰면 안될까? 이 내용은 사실 GC와 관련이 있다.\n아래와 같은 상황이라 가정해보자.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/MZw7rIs.png\">\n</p>\n<p align=\"center\">\n    <em>그림 8. 자바 힙 내에서 레퍼런스가 끊겼지만 회수는 안된 상황</em>\n</p>\n<ol>\n<li>B, A, C라는 데이터가 할당 된 후에 페이지 캐시에 적재가 되었다.</li>\n<li>B, A, C라는 데이터가 더이상 자바 어플리케이션에서 사용되지 않으나 아직 GC에 의해 수거되기 전이다.</li>\n</ol>\n<p>자 우리는 위에서 스왑-아웃과 스왑-인에 대해서 배웠다. 페이지 캐시에 적재된 페이지가 자주 사용되지 않으면 스왑 영역으로 이동된다는 점 말이다.</p>\n<p>그러면 아래와 같이 예상할 수 있다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/LeJbSEA.png\">\n</p>\n<p align=\"center\">\n    <em>그림 9. 운영체제가 먼저 스왑 아웃을 하여 실제 GC 발생 시 Disk I/O가 발생하는 상황</em>\n</p>\n<p>스왑-아웃을 통해서 스왑 영역으로 이동한 페이지가 실제 JVM이 GC를 트리거하게되면 이 내용을 찾기 위해서 다시 스왑-인을 해야될 것이다.</p>\n<p>즉, <strong>STW가 매우 길게 발생</strong>할 수 있다.이 점이 스왑영역을 JVM 어플리케이션이 최소화시키는 이유라 볼 수 있다.</p>\n<h1 id=\"step-3-결론\" style=\"position:relative;\"><a href=\"#step-3-%EA%B2%B0%EB%A1%A0\" aria-label=\"step 3 결론 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 3. 결론</h1>\n<p>어쩌다보니 긴 글이 되었는데 정리를 하자면 아래와 같다.</p>\n<ol>\n<li>가상 메모리를 통한 Disk I/O는 SSD, NVMe를 사용해도 RAM과 비교해서 여전히 느리다.</li>\n<li>1에 의거해서 운영체제의 페이지 캐시를 스와핑하는 작업은 비용이 상당히 높은 작업이다.</li>\n</ol>\n<p>하지만 그럼에도 처리량이 높아야하는 요구사항을 갖는 자바 어플리케이션은 페이지 캐시를 사용한다. 그 이유는 아래와 같다.</p>\n<ol>\n<li>자바 메모리의 GC 패널티가 매우 크다.</li>\n<li>자바 어플리케이션 재시작 시 데이터 유실 문제 및 웜업 작업등의 추가 작업이 필요하다.</li>\n</ol>\n<p>그럼에도 스와핑은 Disk I/O와 GC를 사용할 적에 문제점이 생길 수 있으니 사용하더라도 최소화해서 쓰는 방식이 선호되고 있다.</p>\n<p>긴 글 읽느라 다들 고생 많으셨습니다.</p>\n<h2 id=\"step-31-추신\" style=\"position:relative;\"><a href=\"#step-31-%EC%B6%94%EC%8B%A0\" aria-label=\"step 31 추신 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 3.1 추신</h2>\n<p>이 내용을 정리한 계기가 되었던 부분은 아래의 글 때문입니다.</p>\n<ul>\n<li><a href=\"https://blog.mikemccandless.com/2011/04/just-say-no-to-swapping.html\">Just say no to swapping! - Michael McCandless</a></li>\n</ul>\n<p>근데, 해당 글이 작성년도는 2011년으로 확인됩니다. (Java 7 사용 시점쯤에 작성된 글)\n그러나, 결론 부에 제가 그린 그림은 G1GC의 Region과 같이 구성되어있습니다.</p>\n<p>이 부분에 대해서 제가 실제 검증은 하지 않았지만, 현재까지도 위와 같이 발생할 수 있는 문제가 있지않을까? 추론해서 그린 그림입니다. 그러면 해당 추론이 합리적일까요?</p>\n<ol>\n<li><a href=\"https://www.gridgain.com/docs/latest/perf-troubleshooting-guide/memory-tuning#tune-swappiness-setting\">Memory and JVM Tuning - GridGain Doc</a></li>\n</ol>\n<p>위 가이드에서는 아래와 같이 작성되어있습니다.</p>\n<blockquote>\n<p>The value of this setting can prolong GC pauses as well.\nFor instance, if your GC logs show low user time, high system time, long GC pause records, it might be caused by Java heap pages being swapped in and out. To address this, use the swappiness settings above.</p>\n</blockquote>\n<p>따라서, 실제 GC 시간이 스왑-인/아웃으로 느려질 수 있다는 점을 시사한다고 봅니다.</p>\n<ol start=\"2\">\n<li><a href=\"https://www.slideshare.net/HyojeongLee6/paperdesign-of-swapaware-java-virtual-machine-garbage-collector-policy\">Design of Swap-aware Java Virtual Mache Garbage Collector Policy</a></li>\n</ol>\n<p>위 링크는 JVM GC 중에 발생하는 시스템 스왑의 영향도와 그것에 대한 해결법에 대한 논문의 요약 슬라이드입니다.</p>\n<p>논문 자체를 보진 않아서 슬라이드만 참고하면 G1GC는 아니고 Parallel GC(Mark-and-Summary Compaction이 슬라이드 뒷편에 기술되어있어서) 기준인거 같긴합니다. 어찌됐든 GC와 스왑영역에 대해서 확실한 영향도가 있음을 시사하고 있습니다.</p>\n<ol start=\"3\">\n<li><a href=\"https://www.mastertheboss.com/java/tuning-java-applications-on-linux/\">Tuning Java application on Linux</a></li>\n</ol>\n<p>해당 링크에서는 자바 어플리케이션이 현재 스왑을 사용하는지 확인할 수 있는 스크립트를 제공해주고, 병목지점으로 스왑이 식별될 시 대처법을 설명하고 있습니다.</p>\n<p>위 같은 다양한 사례를 보면 G1GC에도 충분히 적용될 사례로 보이는데 시간이 난다면 해당 내용에 대한 검증을 추가해보겠습니다.</p>\n<h1 id=\"step-4-참고자료\" style=\"position:relative;\"><a href=\"#step-4-%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C\" aria-label=\"step 4 참고자료 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 4. 참고자료</h1>\n<ol>\n<li><a href=\"https://www.quora.com/If-you-have-a-super-fast-NVMe-M-2-SSD-for-virtual-memory-caching-or-swap-files-do-you-still-need-a-lot-of-physical-RAM\">If you have a super fast NVMe M.2 SSD for virtual memory (caching, or swap files), do you still need a lot of physical RAM?</a></li>\n<li><a href=\"https://askubuntu.com/questions/652337/why-are-swap-partitions-discouraged-on-ssd-drives-are-they-harmful\">Why are swap partitions discouraged on SSD drives, are they harmful?</a></li>\n<li><a href=\"https://kwonnam.pe.kr/wiki/linux/ubuntu/hibernation\">Ubuntu Linux Hibernation</a></li>\n<li><a href=\"https://resilient-923.tistory.com/397\">운영체제(OS) 스와핑(swapping), 가상메모리(virtual memory) 란? - 빠르고 꾸준하게</a></li>\n<li><a href=\"https://brunch.co.kr/@alden/14\">메모리 재할당과 커널 파라미터 - 강진우님</a></li>\n<li><a href=\"https://blog.mikemccandless.com/2011/04/just-say-no-to-swapping.html\">Just say no to swapping! - Michael McCandless</a></li>\n<li><a href=\"https://www.elastic.co/kr/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time\">Elasticsearch 캐싱 심층 분석 : 한 번에 하나의 캐시로 쿼리 속도 향상 - elastic.co</a></li>\n<li><a href=\"https://brunch.co.kr/@alden/32\">dirty page 동기화 #1 - 강진우님</a></li>\n<li><a href=\"https://www.gridgain.com/docs/latest/perf-troubleshooting-guide/memory-tuning#tune-swappiness-setting\">Memory and JVM Tuning - GridGain Doc</a></li>\n<li><a href=\"https://www.slideshare.net/HyojeongLee6/paperdesign-of-swapaware-java-virtual-machine-garbage-collector-policy\">Design of Swap-aware Java Virtual Mache Garbage Collector Policy</a></li>\n<li><a href=\"https://www.mastertheboss.com/java/tuning-java-applications-on-linux/\">Tuning Java application on Linux</a></li>\n</ol>\n<div class=\"footnotes\">\n<hr>\n<ol>\n<li id=\"fn-1\"><a href=\"https://en.wikipedia.org/wiki/Device_file#Block_devices\">Block Devices - Wikipedia</a><a href=\"#fnref-1\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-2\"><a href=\"https://en.wikipedia.org/wiki/Disk_cache\">Disk cache - Wikipedia</a><a href=\"#fnref-2\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-3\"><a href=\"https://en.wikipedia.org/wiki/Page_cache\">Page cache - Wikipedia</a><a href=\"#fnref-3\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-4\"><a href=\"https://jojoldu.tistory.com/415\">더티 체킹(Dirty Checking)이란? - 기억보단 기록을</a><a href=\"#fnref-4\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-5\"><a href=\"https://lemp.io/what-is-a-dirty-page-in-operating-system/\">What are dirty pages? - lemp.io</a><a href=\"#fnref-5\" class=\"footnote-backref\">↩</a></li>\n</ol>\n</div>","excerpt":"STEP 1.1 과거의 이야기 STEP 1.2 번외) NVMe를 스왑 영역으로 잡으면 RAM과 속도가 비슷할까? STEP 2.1 운영체제의 캐시 영역과 스와핑 STEP 2.1.1 캐시영역 STEP 2.1.2 스와핑 STEP 2.1.3 운영체제의 메모리 재할당 방식 STEP 2.2 자바, 페이지 캐시 그리고 가비지 컬렉션 STEP 2.2.1 페이지 캐시와 더티 페이지 동기화 STEP 2.2.2 자바 메모리와 가비지 컬렉션 STEP 3.1 추신 STEP 1. 서론 STEP 1.1 과거의 이야기 STEP 1.2 번외) NVMe를 스왑 영역으로 잡으면 RAM과 속도가 비슷할까? STEP 2. 본론 STEP 2.1 운영체제의 캐시 영역과 스와핑 STEP 2.1.1 캐시영역 STEP 2.1.2 스와핑 STEP 2.1.3 운영체제의 메모리 재할당 방식 STEP 2.2 자바, 페이지 캐시 그리고 가비지 컬렉션 STEP 2.2.1 페이지 캐시와 더티 페이지 동기화 STEP 2.2.2 자바 메모리와…","frontmatter":{"date":"June 19, 2023","title":"왜 처리량이 중요한 JVM 어플리케이션은 vm.swappiness = 1로 설정하라고 할까?","categories":"개발 인프라","author":"개발한입","emoji":"💻"},"fields":{"slug":"/fundamental-os-page-cache/"}},"next":{"id":"e998a957-d71c-5e82-94b1-2e6d9da2e186","html":"<h1 id=\"개요\" style=\"position:relative;\"><a href=\"#%EA%B0%9C%EC%9A%94\" aria-label=\"개요 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>개요</h1>\n<p align=\"center\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 128.33333333333331%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAaABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAEDBQIE/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAdaziiPehWfOgAP/xAAbEAACAwADAAAAAAAAAAAAAAABAwIREgAgIf/aAAgBAQABBQLdSDI1zJvVsHgayUwhVHp//8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAHhAAAQMEAwAAAAAAAAAAAAAAAQACERASMUEgIeH/2gAIAQEABj8C9XZihygwOmd0DQxwuV2NY4//xAAeEAEAAgEEAwAAAAAAAAAAAAABABExIUFRYRBxkf/aAAgBAQABPyFuYzvKNAuFg2WTWro9kCoELVIKC17ZY8+5rXqMwMMqPyEo48//2gAMAwEAAgADAAAAEF/FDP/EABURAQEAAAAAAAAAAAAAAAAAACAx/9oACAEDAQE/EKP/xAAVEQEBAAAAAAAAAAAAAAAAAAABIP/aAAgBAgEBPxBQj//EAB4QAQACAgMAAwAAAAAAAAAAAAEAESExQVFxEJGh/9oACAEBAAE/ENZwRhMD1BDy4GGACCJYnMTebKVg+yXeoD0mxK/e2Oi09GFVdwNJaoccYYK5NNwA34t9gAxAGwC7Q38AGgJ//9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"book\" title=\"book\" src=\"/static/f4f6fe8b15134e4dd75cbe77ae3aeaa3/80e3c/book.jpg\" srcset=\"/static/f4f6fe8b15134e4dd75cbe77ae3aeaa3/4ec73/book.jpg 180w,\n/static/f4f6fe8b15134e4dd75cbe77ae3aeaa3/158ba/book.jpg 360w,\n/static/f4f6fe8b15134e4dd75cbe77ae3aeaa3/80e3c/book.jpg 720w,\n/static/f4f6fe8b15134e4dd75cbe77ae3aeaa3/b701e/book.jpg 934w\" sizes=\"(max-width: 720px) 100vw, 720px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n</p>\n<p>벌써, 1년 6개월 정도 진행 중인 스터디가 있다. 각자 읽고 싶은 책을 투표하여 완독을 목표로 하는 스터디로 간단하게 삼색볼펜법<sup id=\"fnref-1\"><a href=\"#fn-1\" class=\"footnote-ref\">1</a></sup>을 통해서 진행되고 있다.</p>\n<p>읽은 책의 목록은 아래와 같다.</p>\n<ol>\n<li><a href=\"http://www.yes24.com/Product/Goods/74219491\">오브젝트</a></li>\n<li><a href=\"http://www.yes24.com/Product/Goods/77283734\">클린아키텍처</a></li>\n<li><a href=\"http://www.yes24.com/Product/Goods/4667932\">대규모 서비스를 지탱하는 기술</a></li>\n<li><a href=\"http://www.yes24.com/Product/Goods/104491433\">소프트웨어 아키텍처 101</a></li>\n<li><a href=\"http://www.yes24.com/Product/Goods/59566585\">데이터 중심 어플리케이션 설계</a></li>\n<li><a href=\"http://www.yes24.com/Product/Goods/11681152\">클린코드</a></li>\n<li><a href=\"http://www.yes24.com/Product/Goods/65551284\">이펙티브 자바</a></li>\n</ol>\n<p>다른 도메인의 현직 개발자분들과 같은 책을 읽으면서 서로 궁금한 부분이나 토론을 통해서 진행하면서 많은 인사이트를 얻게된 스터디라고 생각이 든다.</p>\n<p>현재 우리가 읽고 있는 책은 <a href=\"http://www.yes24.com/Product/Goods/99423020\">이벤트 기반 마이크로서비스 구축</a>이라는 책이다.\n이직 한 후에 재직 중인 회사의 서비스가 매우 비슷한 아키텍처로 되어있고, 흥미롭게 볼 수 있었다.</p>\n<p>그런데 읽다보니 스트리밍 시스템 <sup id=\"fnref-2\"><a href=\"#fn-2\" class=\"footnote-ref\">2</a></sup> 이라는 내용이 자주나오는 것을 확인하였다.\n이 부분에 대해서 다른 스터디원 한분이 아래와 같은 질문을 하였다.</p>\n<blockquote>\n<p>배치 프로세싱과 스트리밍 프로세싱은 정확히 어떤 부분이 다른걸까요?</p>\n</blockquote>\n<p>사실 이 부분은 어렴풋한 차이만 말을 할 수 있었고, 이 부분에 대해서 정확하게 나 또한 말을 할 수 없었다.\n더 나아가 스트리밍 시스템과 기존 어플리케이션, 백엔드 서비스와의 차이도 알고 싶었고 이벤트 주도 아키텍처(Event-Driven Architecture) <sup id=\"fnref-3\"><a href=\"#fn-3\" class=\"footnote-ref\">3</a></sup> 와 스트리밍 시스템도 차이를 가지는가에 대해서 궁금하였다.</p>\n<p>이번 포스팅은 위에 대한 궁금증을 해소하고, 간단한 스트리밍 시스템의 예시를 들어보고자 한다.</p>\n<h1 id=\"스트리밍-시스템-톺아보기\" style=\"position:relative;\"><a href=\"#%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D-%EC%8B%9C%EC%8A%A4%ED%85%9C-%ED%86%BA%EC%95%84%EB%B3%B4%EA%B8%B0\" aria-label=\"스트리밍 시스템 톺아보기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>스트리밍 시스템 톺아보기</h1>\n<ul>\n<li>STEP 1. 분산 시스템(Distribution System)의 대두\n<ul>\n<li>STEP 1.1 이벤트 주도 아키텍처(Event-Driven Architecture)란?\n<ul>\n<li>STEP 1.1.1 메시지와 이벤트</li>\n<li>STEP 1.1.2 정리</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>STEP 2. 스트리밍 시스템(Streaming System)이란?\n<ul>\n<li>STEP 2.1 Bounded Data vs Unbounded Data</li>\n<li>STEP 2.2 Stream Processing</li>\n<li>STEP 2.3 스트리밍 시스템 vs 전통적인 아키텍처\n<ul>\n<li>STEP 2.3.1 어플리케이션(Application)</li>\n<li>STEP 2.3.2 백엔드 서비스(Back-End Service)</li>\n<li>STEP 2.3.3 배치 프로세싱(Batch Processing)</li>\n</ul>\n</li>\n<li>STEP 2.4 정리</li>\n</ul>\n</li>\n<li>STEP 3. 간단한 스트리밍 시스템</li>\n<li>STEP 4. REFERENCE</li>\n</ul>\n<h2 id=\"step-1-분산-시스템distribution-system의-대두\" style=\"position:relative;\"><a href=\"#step-1-%EB%B6%84%EC%82%B0-%EC%8B%9C%EC%8A%A4%ED%85%9Cdistribution-system%EC%9D%98-%EB%8C%80%EB%91%90\" aria-label=\"step 1 분산 시스템distribution system의 대두 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 1. 분산 시스템(Distribution System)의 대두</h2>\n<p>먼저, 이벤트 주도 아키텍처가 탄생한 배경에 대해서 아는 것이 중요하다고 생각한다.\n이 내용은 <strong>내 개인적인 생각이기때문에 당연히 틀릴 수 있는 부분이라고 생각하니</strong>, 다양한 책들을 통해서 왜 이러한 아키텍처가 대두되어왔는가에 대해서 생각하는 것이 중요하다고 본다.</p>\n<p>먼저, 이전에 작성했던 <a href=\"https://brewagebear.github.io/concurrency-distributed-transaction-with-tcc/\">개발한입 - 동시성 문제 해결 전략 - 스프링으로 구현한 TCC 패턴</a> 글을 보면, 우리는 분산 트랜잭션의 핸들링의 어려움을 겪고 있고 이에 대해서 SAGA<sup id=\"fnref-4\"><a href=\"#fn-4\" class=\"footnote-ref\">4</a></sup> 패턴이나 TCC패턴, Two-Phase Commit<sup id=\"fnref-5\"><a href=\"#fn-5\" class=\"footnote-ref\">5</a></sup> 등이 나오게 되었다.</p>\n<p>위 포스팅에서 작성하지 않는 부분이 있는데 바로 <strong>왜 분산 시스템으로 가게되었는가?</strong> 이다.</p>\n<p>이 내용은 <a href=\"https://d2.naver.com/helloworld/206816\">Naver D2- 확장성 있는 웹 아키텍처와 분산 시스템</a> 에 매우 잘나와있다. 자세한 내용은 해당 본문을 참고하도록 하고, 여기서는 중요한 부분들만 짚어보도록 하자.</p>\n<blockquote>\n<p>일단, 분산 시스템이 대두된 원인은 단순했던 웹서비스가 <strong>서비스의 사용자 증가 혹은 복잡도가 증대</strong>되면서 신뢰성(Reliability)이나 확장성(Scalability), 가용성(Availability)등을 확보하기위함이라고 볼 수 있다.</p>\n</blockquote>\n<p>즉, 기존의 아키텍처로는 해결이 안되기 때문에 <strong>분산 시스템을 사용하자</strong>라는 개념이 대두된 것이다.\n네이버 D2 글에서는 이미지 호스팅 서비스를 예시를 들어서 이 서비스가 어떻게 진화해나가는 지 잘 서술되어있다.</p>\n<p>우리가 초점으로 볼 부분은 쓰기에 대한 부하를 감당하기 위해서 위 본문에서는 큐를 도입했는데 이 내용을 주로 보고자 한다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/VUffWgC.png\">\n</p>\n<p align=\"center\">\n<em>그림 1. 전통적인 클라이언트-서버의 요청 구조 (동기식 처리)</em>\n</p>\n<p>위는 전통적인 클라이언트-서버 구조의 요청, 응답 구조이며, 아래와 같다.</p>\n<ol>\n<li>클라이언트는 서버에게 요청을 보낸다.</li>\n<li>서버는 해당 요청을 읽은 후 알맞은 응답을 보낸다.</li>\n<li>이는 <strong>동기적(Synchronous)</strong> 으로 처리된다.</li>\n</ol>\n<p>동기적 요청에 대해 이해가 안간다면 <a href=\"https://brewagebear.github.io/fundamental-nio-and-io-models/#step-41-io-%EB%AA%A8%EB%8D%B8\">개발한입 - 자바 NIO의 동작원리 및 IO 모델(STEP 4.1 I/O 모델) </a>을 참고해보자.</p>\n<p>이러한 구조로 가게 되었을 경우에 당연히 서버쪽에 많은 요청이 들어오게 될 경우 병목현상(Bottlenack)<sup id=\"fnref-6\"><a href=\"#fn-6\" class=\"footnote-ref\">6</a></sup> 이 발생할 수 있으며, 병목현상이 발생할 경우 블록킹이 되기에 응답지연과 같은 문제가 발생하여 클라이언트의 경험이 상당히 저하가될 수 있다.</p>\n<p>이를 해결하기 위해서 비동기적 처리를 할 수 있지만 이는 구현하기 까다롭다는 문제가 있다. 이때 우리는 메시지 브로커(Message-Broker)<sup id=\"fnref-7\"><a href=\"#fn-7\" class=\"footnote-ref\">7</a></sup> 를 활용하여 처리할 수 있다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/r6VbbXt.png\">\n</p>\n<p align=\"center\">\n<em>그림 2. 메시지 브로커를 통한 비동기식 처리</em>\n</p>\n<p>위와 같이 처리함으로써 서버 요청을 부하를 메시지 브로커를 통해서 줄일 수 있으며, 비동기식(Ansychronous) 처리가 가능하므로  클라이언트는 작업요청을 보낸 후 기다리지 않고 다른 작업을 진행하다가 응답을 통해서 처리가 가능하다는 장점이 있다.</p>\n<p>핵심적인 차이는 <strong>동기적 처리가 아닌 비동기적인 처리</strong>를 할 수 있으며, 메시지브로커를 통해서 클라이언트-서버간의 <strong>결합도(Coupling)을 줄일 수 있다는 점</strong>이다.</p>\n<p>갑자기 메시지 브로커 이야기를 하게되었는데 이벤트 주도 아키텍처를 알기 위해서는 위의 핵심 내용이 필요하기 때문이다.</p>\n<p>이제, 이벤트 주도 아키텍처에 대해서 알아보자.</p>\n<h3 id=\"step-11-이벤트-주도-아키텍처event-driven-architecture란\" style=\"position:relative;\"><a href=\"#step-11-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%A3%BC%EB%8F%84-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98event-driven-architecture%EB%9E%80\" aria-label=\"step 11 이벤트 주도 아키텍처event driven architecture란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 1.1 이벤트 주도 아키텍처(Event-Driven Architecture)란?</h3>\n<p>위에서 간단하게 쓰기 부하에 대해서 동기식 처리에 대한 단점이 존재하여, 메시지 브로커를 통해서 비동기식 처리로 변경하는 부분에 대해서 설명하였다.</p>\n<p>이벤트 주도 아키텍처를 설명하기 전에 아래와 같이 가정을 해보자.</p>\n<blockquote>\n<p>우리 서비스는 이제 메시지 브로커 도입을 통해서 비동기식 방식으로 처리가 잘 이루어지고 있었다.</p>\n<p>하지만 서비스가 성장함에 따라 서버 내에 어떤 서비스(Bear Service)에 대한 처리가 느려지는 문제가 대두 되었다.</p>\n<p>이에 reply 메시지 브로커에 인입되는 메시지처리 속도가 느려졌고, 이에 사용자 경험은 또다시 떨어지게 되었다. 수많은 토론 끝에 내린 결론은 메시지 처리가 느린 서비스를 독립적인 모듈화를 시켜서 스케일 아웃을 진행하는 것이었다.</p>\n<p>이 구조로 갈 경우 주요한 이슈는 독립된 모듈 서비스에서 처리한 내용을 다시 원래 서비스에서 받아서 처리를 해서 다시 클라이언트에 가야하는 구조이라는 점이다.</p>\n</blockquote>\n<p align=\"center\">\n <img src=\"https://i.imgur.com/ha2WARw.png\">\n</p>\n<p align=\"center\">\n<em>그림 3. 복잡해진 아키텍처와 응답 처리 문제</em>\n</p>\n<p>위의 경우에도 서버가 만약 동기식 요청을 해당 서비스에서 던지게 될 경우에는 또 다시 블록킹이 발생할 수 있다.\n아주 단순하게 생각하면 저 부분에도 메시지 브로커를 도입하면 된다.</p>\n<p align=\"center\">\n\t<img src=\"https://i.imgur.com/TQKtavo.png\">\n</p>\n<p align=\"center\">\n<em>그림 4. 메시지 브로커를 통한 복잡한 아키텍처의 문제 해결</em>\n</p>\n<p>이렇게 하면서 얻는 이점은 서버와 분리된 서비스간의 결합도가 낮아지고, 비동기식 처리가 가능하다는 점이다.\n여기까지 봤을 때 눈치를 채었는가?</p>\n<blockquote>\n<p>이벤트 주도 아키텍처는 위와 같이 각 모듈간의 결합도를 낮추고, 비동기 처리를 통해서 해당 요청들을 알맞은 책임에게 던질 수 있는 아키텍처를 말한다.</p>\n</blockquote>\n<h3 id=\"step-111-메시지message와-이벤트event\" style=\"position:relative;\"><a href=\"#step-111-%EB%A9%94%EC%8B%9C%EC%A7%80message%EC%99%80-%EC%9D%B4%EB%B2%A4%ED%8A%B8event\" aria-label=\"step 111 메시지message와 이벤트event permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 1.1.1 메시지(Message)와 이벤트(Event)</h3>\n<p>그렇다면? 이벤트 주도 아키텍처의 이벤트(Event)는 무엇을 뜻하는 것일까?\n이벤트는 수 많은 내용을 포함하고 있다. 마우스를 움직이는 것이나 버튼을 클릭하는 것 혹은 요청을 보내는 것 등등..</p>\n<p>컴퓨팅 영역에서는 어떤 input 자체를 이벤트라고 뜻할 수 있다고 본다.</p>\n<p>여기서 또 궁금한 점이 생겼다. 그렇다면 메시지와 이벤트는 무엇이 다른것일까?\n구글링을 하면서 Akka<sup id=\"fnref-8\"><a href=\"#fn-8\" class=\"footnote-ref\">8</a></sup> 프레임워크의 개발사인 Lightbend<sup id=\"fnref-9\"><a href=\"#fn-9\" class=\"footnote-ref\">9</a></sup>의 공식 문서에서 이를 다루는 것을 확인하였다.</p>\n<blockquote>\n<p>A Message is some data sent to a specific address. In Message Driven systems, each component has a unique address other components can send messages to. Each of these components, or recipients, awaits messages and reacts to them.</p>\n<p>An Event is some data emitted from a component for anyone listening to consume.</p>\n</blockquote>\n<p>위의 내용을 요약하면 메시지는 택배기사가 택배를 정해진 위치에 배송하는 것과 유사하며, 이벤트는 해당 이벤트에 대한 내용을 구독하고 있는 모든 사용자를 위해 방출되는 데이터라고 볼 수 있다.</p>\n<p>하지만, 대부분의 이벤트 주도 아키텍처를 보면 메시지 브로커든 메시지 큐 등을 사용한 내용을 볼 수 있다.</p>\n<p>사실, 엄밀히 따져서 메시지는 송신 주체와 수신 주체가 명확한 것이고 이벤트는 그것이 명확하지 않은 것이다.\n즉, 이벤트가 더 추상화된 상위개념이고 메시지는 이 이벤트를 담아서 송신과 수신을 처리해주는 녀석이라고 볼 수 있다.</p>\n<p>이해가 안될 수 있으니 아래와 같이 볼 수 있다고 생각한다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/O0RZZ5u.png\">\n</p>\n<p align=\"center\">\n<em>그림 4. 메시지와 이벤트</em>\n</p>\n따라서, 목적지와 수신지를 처리하기 위해서는 메시지가 필요하고, 메시지안에 이벤트가 담기는 형식이라고 생각한다. \n<p>자세한 내용은\n<a href=\"https://developer.lightbend.com/docs/akka-guide/concepts/message-driven-event-driven.html#_events_are_messages\">LightBend-Events ars messages</a> 내용을 읽어보도록 하자.</p>\n<p>여기서도 메시지 주도 아키텍처는 보다 시스템 구성 요소적인 측면이 강하고, 이벤트 주도 아키텍처가 보다 추상화된 내용이라고 말한다.</p>\n<blockquote>\n<p>즉, 메시지 주도 아키텍처로도 이벤트 주도 아키텍처를 구현할 수 있다.\nSo, using Message Driven tools we can build an Event Driven system.</p>\n</blockquote>\n<p>좀 더 상세한 차이를 이해하고 싶다면 아래의 아티클을 추천한다.</p>\n<ul>\n<li><a href=\"https://medium.com/event-driven-utopia/using-commands-events-and-queries-in-microservices-communication-3573f1fcfafe\">Medium - Using Commands, Events, and Queries in Microservices Communication</a></li>\n</ul>\n<h3 id=\"step-112-이벤트-주도-아키텍처-정리\" style=\"position:relative;\"><a href=\"#step-112-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%A3%BC%EB%8F%84-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%A0%95%EB%A6%AC\" aria-label=\"step 112 이벤트 주도 아키텍처 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 1.1.2 이벤트 주도 아키텍처 정리</h3>\n<p>결국 핵심은 발전해가고 복잡해지는 소프트웨어 아키텍처에서 개선점들이 생겨나면서 이러한 아키텍처가 생긴 것이라고 볼 수 있다.</p>\n<p>파티셔닝과 샤딩, 프록시, 캐시등을 제외하고 해당 글에서 다룬 내용을 토대로 시스템 발전 과정의 히스토리를 봐보자.</p>\n<ul>\n<li><strong>분산 아키텍처는 왜 대두되었는가?</strong>\n<ul>\n<li>이유 : 기존 모놀리틱 시스템의 문제점들이 점점 발생 (복잡도 증대 및 유지보수의 어려움)</li>\n<li>결론 : 각각의 서비스를 독립적으로 분리시키자 (SOA, MSA 등이 대두)</li>\n</ul>\n</li>\n<li><strong>하지만 동기적인 API 요청의 단점이 존재하였다.</strong>\n<ul>\n<li>이유 : 요청을 서버에서 처리하는 동안 클라이언트는 블록킹이 발생한다.</li>\n<li>결론 : 비동기적인 처리를 하자 -> 구현의 복잡도를 낮추고 결합도를 낮추기 위해 메시지 브로커 등을 도입</li>\n</ul>\n</li>\n</ul>\n<p>따라서 핵심은 이벤트 브로커나 메시지 브로커등에 이벤트를 발생해서 비동기적으로 처리하여 각 서비스간의 결합도를 낮추고, 블록킹을 줄인 시스템이 이벤트 주도 아키텍처라 볼 수 있다.</p>\n<p>위의 내용은 많은 내용이 생략이 되었고, 본문에서 다룬 내용을 다시 재정리한 내용이다.\n따라서 꼭 아래의 글을 읽기를 추천한다.</p>\n<ol>\n<li><a href=\"https://d2.naver.com/helloworld/206816\">Naver D2- 확장성 있는 웹 아키텍처와 분산 시스템</a></li>\n<li><a href=\"https://medium.com/dtevangelist/event-driven-microservice-%EB%9E%80-54b4eaf7cc4a\">Medium - Event Driven Architecture란?</a></li>\n</ol>\n<h2 id=\"step-2-스트리밍-시스템\" style=\"position:relative;\"><a href=\"#step-2-%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D-%EC%8B%9C%EC%8A%A4%ED%85%9C\" aria-label=\"step 2 스트리밍 시스템 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2. 스트리밍 시스템</h2>\n<p>먼저, 스트리밍 시스템을 이해하기 위해서는 유한 데이터(Bounded Data)와 무한 데이터(Unbounded Data)를 알아야한다.</p>\n<p>개인적으로 이 번역은 매우 잘못되어있다고 생각이 드는데 실제 번역서 중에서 Unbounded Data를 무한 데이터로 해놓은 책이 매우 많아서 이해하기가 매우 힘들었다.</p>\n<p>무한 데이터란 무엇인가? 사실 원어인 Unbounded Data를 보았을 때는 무엇인가 Bound가 결정되지 않은 즉, 언제 시작되고 언제 끝날지 모르는 그리고 실시간성 로그 데이터들이라고 볼 수 있다. 하지만, 번역서 중에는 이 내용을 원어가 없이 표기한 책이 많았고 이 때문에 어려움을 많이 겪었다.</p>\n<p>그래서 이 포스팅에서는 유한, 무한데이터보다는 원어 표기인 Bounded Data, Unbouned Data의 표기를 따르도록 하겠다.</p>\n<p>그렇다면? Bounded Data와 Unbounded Data는 무슨 차이일까?</p>\n<h3 id=\"step-21-bounded-data-vs-unbounded-data\" style=\"position:relative;\"><a href=\"#step-21-bounded-data-vs-unbounded-data\" aria-label=\"step 21 bounded data vs unbounded data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.1 Bounded Data vs Unbounded Data</h3>\n<p>이 내용은 <a href=\"http://www.yes24.com/Product/Goods/59566585\">멧돼지책(데이터 중심 어플리케이션 설계)</a>에도 나오는 내용이다.</p>\n<blockquote>\n<p>In reality, a lot of data is unbounded because it arrives gradually over time: your users produced data yesterday and today, and they will continue to produce more data tomorrow. Unless you go out of business, this process never ends, and so the dataset is never “complete” in any meaningful way.</p>\n<p>— Martin Kleppmann, Designing Data-Intensive Applications</p>\n</blockquote>\n<p><strong>즉, Unbounded Data는 데이터의 수가 정해져(unbounded)있지않고, 계속 변경될 수 있는 데이터</strong>를 말한다.</p>\n<ul>\n<li>이는 증권 거래 체결 내역이나 인스타그램의 피드 그리고 실시간 데이터 로그등이 속한다고 볼 수 있다.</li>\n</ul>\n<p>그렇다면 <strong>Bounded Data는 무엇일까? 데이터의 수가 정해진 데이터</strong>를 뜻한다.</p>\n<ul>\n<li>주간 정산 데이터, 월간 사용자 수 통계 등</li>\n</ul>\n<p>내가 제일 헷갈린 것이 <strong>Bounded</strong> 개념이였는데 시간을 일정 바운드로 둔다면, 실시간 로그들도 일정 바운드에 갇히게 되는 것 아닌가? 라고 생각하였다. 그렇게 생각하다보니 이해가 어려웠는데 핵심은 <strong>데이터의 수</strong>라고 보면될 것 같다.</p>\n<p>즉, <strong>데이터 수나 변경에 열려있는 것이 Unbounded data 데이터, 닫혀있는 것이 Bounded data라 보면 될 것 같다</strong>.</p>\n<p>그렇다면 위에서 다뤘던 이벤트는 Bounded Data일까? Unbounded Data일까?\n이벤트는 언제 발생할지 모르고 동일한 이벤트여도 이전 이벤트와 동일한 데이터 수를 가진다고 기대할 수 없으므로 <strong>Unbounded Data</strong>에 가깝다고 볼 수 있다.</p>\n<p>자 이제 Unbounded Data와 Bounded Data를 차이를 알았다.\n그렇다면 이제 다시 스트리밍 시스템에 대해 알기 위해서 스트리밍 프로세싱에 대해 알아보자.</p>\n<h3 id=\"step-22-stream-proccesing\" style=\"position:relative;\"><a href=\"#step-22-stream-proccesing\" aria-label=\"step 22 stream proccesing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.2 Stream Proccesing</h3>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/MrymtMY.jpg\">\n</p>\n<p align=\"center\">\n<em>그림 5. Grokking Streaming Systems : Real-time event Processing</em>\n</p>\n<p>이 부분부터는 <a href=\"http://www.yes24.com/Product/Goods/99423020\">이벤트 기반 마이크로 서비스 구축</a>보다는 <a href=\"https://a.co/d/9zb7Tml\">Grokking Streaming Systems: Real-time event processing</a> 책을 많이 참고하였다.</p>\n<p>이 책에서는 스트리밍 프로세스를 아래와 같이 정의한다.</p>\n<blockquote>\n<p>Stream Proccssing has been one of the most popular technologies in the recent years in the big data domain. Streaming systems are the computer systems that process continuous event streams.</p>\n<p>— Josh Fischer, Grokking Streaming Systtems : Real-time event Processing p.31</p>\n</blockquote>\n<p>즉, 지속적으로 발생하는 이벤트 스트림을 처리하는 작업이 바로 스트리밍 시스템이다.\n그림으로 보면 아래와 같다고 볼 수 있다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/8VcZArn.jpg\">\n</p>\n<p align=\"center\">\n<em>그림 6. 스트리밍 시스템 예시, Grokking Streaming Systems : Real-time event Processing, p.36</em>\n</p>\n<p>이벤트 주도 아키텍처는 이벤트를 통해서 처리되는 아키텍처라고 위에서 설명을 하였다. 그렇다면, 이벤트 주도 아키텍처와 스트리밍 시스템의 차이는 무엇인가?</p>\n<p>틀린 생각일 수도 있지만 개인적으로 <strong>스트리밍 시스템 ⊂ 이벤트 주도 아키텍처</strong>와 같은 부분집합이라고 보면 될 것 같다. 즉, 이벤트 주도 아키텍처 내부에 지속적으로 발생하는 이벤트 스트림을 처리하는 스트리밍 시스템이 속하는 것이라 생각한다.</p>\n<p>이제 얼추 어떤 느낌인지 감이 올 것이라고 판단된다.\n그렇다면 이 포스팅의 목적이였던 <strong>스트리밍 시스템과 기존 시스템의 차이</strong>를 알 시간이 왔다고 생각한다.</p>\n<p>이에, 전통적인 시스템들과 스트리밍 시스템을 비교해보고자 한다.</p>\n<h3 id=\"step-23-스트리밍-시스템-vs-전통적인-아키텍처\" style=\"position:relative;\"><a href=\"#step-23-%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D-%EC%8B%9C%EC%8A%A4%ED%85%9C-vs-%EC%A0%84%ED%86%B5%EC%A0%81%EC%9D%B8-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98\" aria-label=\"step 23 스트리밍 시스템 vs 전통적인 아키텍처 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.3 스트리밍 시스템 vs 전통적인 아키텍처</h3>\n<h4 id=\"step-231-어플리케이션application\" style=\"position:relative;\"><a href=\"#step-231-%EC%96%B4%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98application\" aria-label=\"step 231 어플리케이션application permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.3.1 어플리케이션(Application)</h4>\n<p>여기서 말하고자하는 어플리케이션의 정의는 아래와 같다.</p>\n<blockquote>\n<p>An application is a computer program that users intract with directly</p>\n<p>— Josh Fischer, Grokking Streaming Systtems : Real-time event Processing p.38</p>\n</blockquote>\n<p>즉, 게임이 될수도 있고 어떤 GUI 환경의 프로그램도 될 수 있다.\n이 책에서는 어플리케이션의 특징을 아래와 같이 꼽는다.</p>\n<ul>\n<li>어플리케이션은 시작점(Starting point)을 갖는다. (어플리케이션 시작 시)</li>\n<li>어플리케이션은 종료점(Ending point)를 갖는다.(어플리케이션 종료 시)</li>\n<li>그리고 메인 루프(Main loop)을 갖는데 메인 루프는 아래의 세가지 단계로 나눠진다.\n<ol>\n<li>사용자의 입력을 받는다.</li>\n<li>로직을 수행한다.</li>\n<li>결과를 보여준다.</li>\n</ol>\n</li>\n</ul>\n<p>그림으로 보면 아래와 같다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/DWxq6Ts.png\">\n</p>\n<p align=\"center\">\n<em>그림 7. 어플리케이션 구조 예시, Grokking Streaming Systems : Real-time event Processing, p.39</em>\n</p>\n<h4 id=\"step-232-백엔드-서비스backend-services\" style=\"position:relative;\"><a href=\"#step-232-%EB%B0%B1%EC%97%94%EB%93%9C-%EC%84%9C%EB%B9%84%EC%8A%A4backend-services\" aria-label=\"step 232 백엔드 서비스backend services permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.3.2 백엔드 서비스(Backend Services)</h4>\n<p>다음으로 볼 아키텍처는 백엔드 서비스이다. 백엔드 서비스에 대해서는 이 책에서는 아래와 같이 정의를 내린다.</p>\n<blockquote>\n<p>A backend service is a computer program that runs behind the scenes.\n— Josh Fischer, Grokking Streaming Systtems : Real-time event Processing p.40</p>\n</blockquote>\n<p>즉, 뒷단에서 작업을 하는 컴퓨터 프로그램이라고 정의를 내리고 있다.\n어플리케이션과 다른 부분은 사용자와 직접적으로 상호작용(interaction)이 이뤄지지 않는다는 점이다.\n대신, 요청에 따라 특정 작업을 수행한다.</p>\n<p>백엔드 서비스는 대부분의 시간을 <strong>요청을 받는 것과 요청을 처리하는 것</strong>에 보낸다.\n이 책에서는 백엔드 서비스의 특징을 아래와 같이 꼽는다.</p>\n<ul>\n<li>백엔드 서비스는 요청을 받는다.</li>\n<li>백엔드 서비스는 요청을 파싱한다.</li>\n<li>파싱된 요청에 따라서 적절한 작업을 수행한다.</li>\n<li>최종적으로 응답의 결과를 보낸다.</li>\n</ul>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/g7MiNPh.png\">\n</p>\n<p align=\"center\">\n<em>그림 8. 전통적인 백엔드 서비스 구조 예시, Grokking Streaming Systems : Real-time event Processing, p.40</em>\n</p>\n<p>위와 같이 서비스는 필요한 작업을 다른 서비스(위의 그림에는 Storage가 된다)에 요청을 보내고 종합하는 식으로도 처리하기도 한다.</p>\n<p>어플리케이션과 동일하게 메인 루프(Main loop)가 존재하지만 요청에 따라 다른 작업을 처리할 필요성이 존재한다. (다양한 요청이 들어올 수 있기때문에) 어플리케이션은 주로 사용자가 단독으로 프로그램을 수행할 가능성이 많지만 백엔드 서비스의 경우에는 많은 사용자들이 요청을 보내고, 또한 요청 자체가 같은 시간에 도착할 수도 있는 동시성 문제가 존재한다.</p>\n<p>이에 대부분의 백엔드 서비스는 멀티 쓰레딩기법을 활용하는 특징을 갖는다. 이를 통해 새로운 요청이 들어오면 쓰레드를 통해서 특정 작업을 통해 수행하도록하여 위와 같은 한계를 극복하였다.</p>\n<p>이렇게 함으로써 메인 루프의 처리량을 쓰레드에 위임하여 보다 빠르게 요청을 응답하게 할 수 있는 것이다.\n따라서, 요즘날의 백엔드 서비스는 아래와 같은 구조를 갖는다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/RD7WLsT.png\">\n</p>\n<p align=\"center\">\n<em>그림 9. 현대의 백엔드 서비스 구조 예시, Grokking Streaming Systems : Real-time event Processing, p.42</em>\n</p>\n<h4 id=\"step-233-배치-프로세싱batch-processing\" style=\"position:relative;\"><a href=\"#step-233-%EB%B0%B0%EC%B9%98-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8B%B1batch-processing\" aria-label=\"step 233 배치 프로세싱batch processing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.3.3 배치 프로세싱(Batch Processing)</h4>\n<p>앞에서 본 어플리케이션과 백엔드 서비스는 사용자의 응답 (혹은 요청)에 최대한 빠르게 응답할 수 있게 설계된 아키텍처라고 생각할 수 있다. 그러나, 배치 프로세싱은 어떤 요청을 처리하기 위해 고안된 아키텍처는 아니다.</p>\n<p>배치 프로세스는 <strong>어떤 작업을 스케줄 시간 혹은 리소스가 허용되었을 때 수행하는 아키텍처</strong>이다.\n주로 배치 프로세스는 대용량 데이터를 처리하기 위해서 사용하곤 한다.</p>\n<p>전통적인 배치 프로세싱의 구조는 아래와 같다고 볼 수 있다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/N4LpZmz.png\">\n</p>\n<p align=\"center\">\n<em>그림 10. 배치 프로세싱 구조 예시, Grokking Streaming Systems : Real-time event Processing, p.44</em>\n</p>\n<p>위의 그림처럼 일정 스케줄이든 어떤 트리거를 통해서 배치 프로세싱이 수행된다면 나눠진 단계별로 배치 프로세싱이 수행된다. 그 과정속에서 데이터베이스나 스토리지 시스템을 통해서 각 단계별 내용을 바로 반영을 하고 다음 단계에서는 이전의 결과가 담겨있는 스토리지 데이터를 참고로 계속해서 작업을 수행한다.</p>\n<p>배치 프로세싱은 모든 단계가 완료되면 끝난다.\n보면 알겠지만 이 배치 프로세싱의 최대의 단점은 <strong>지연시간(latencty)</strong> 이다.</p>\n<p>이것을 풀어쓰자면 배치 프로세싱은 시작하기 전에 매시간 또는 매일과 같이 일정한 간격으로 데이터를 수집하고 배치로 저장해야하고, 특정 시간대에 수집된 모든 이벤트는 처리할 기간이 끝날 때까지 기다려야 한다는 점이다.</p>\n<p>문제는 <strong>이 단점을 수용할 수 없는 케이스들이 존재한다는 점</strong>이다.</p>\n<p>e.g) 서버 실시간 모니터링 시스템, 장애 알림 솔루션 등..</p>\n<p>이러한 사용사례(use-case)들의 특징은 데이터가 받자마자 즉각적으로 처리되는 것을 요구사항으로 갖는다는 점이다. 즉, 실시간이든 준실시간이든 최대한 실시간으로 처리되길 희망하는 사용사례들이다.</p>\n<p>위의 한계를 극복하기 위해서 탄생한 것이 바로 <strong>스트리밍 시스템</strong>이다.</p>\n<h3 id=\"step-24-정리\" style=\"position:relative;\"><a href=\"#step-24-%EC%A0%95%EB%A6%AC\" aria-label=\"step 24 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 2.4 정리</h3>\n<p>배치 프로세싱과 스트리밍 시스템의 차이를 예시를 들면 아래와 같다.</p>\n<ul>\n<li>배치 프로세싱 : 우체국</li>\n<li>스트리밍 시스템 : 공장의 조립 라인</li>\n</ul>\n<p>배치 프로세싱은 <strong>우체국과 같이 많은 우편들을 수집한 뒤에 분류 혹은 적절한 사업소에 배치 작업을 한 뒤에 최종 배달지에서는 정해진 배달 시간에 따라서 전송</strong>을 한다.</p>\n<p>스트리밍 시스템은 <strong>공장의 조립 라인과 같이 여러 단계를 거쳐 단계 마다 새로운 부품을 조립하여 최종 제품을 생산</strong>해낸다.</p>\n<p>전통적인 스트리밍 시스템의 구조는 아래의 그림과 같다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/CewfQLq.png\">\n</p>\n<p align=\"center\">\n<em>그림 11. 전통적인 스트리밍 시스템 구조 예시, Grokking Streaming Systems : Real-time event Processing, p.48</em>\n</p>\n거의 배치 프로세싱의 구조와 흡사한 것으로 볼 수 있다.\n가장 큰 차이는 각 단계는 새로운 데이터가 들어오면 다음 단계로 처리하는 작업을 계속해서 수행하며, 각 이벤트들은 다음 단계로 처리가 되자마자 전달되어 모든 단계가 끝난 후에 최종 결과가 스토리지 시스템에 적재됨을 볼 수 있다.\n<p>비슷한 구조지만 가장 큰 차이점은 아래와 같다.</p>\n<ol>\n<li>배치 프로세싱\n<ul>\n<li>각 단계가 독립적으로 수행되며, 같은 단계여도 서로 독립적으로 수행된다.\n<ul>\n<li>즉, 같은 시간에 모든 단계가 동작하지 않는다.(1번 단계 수행 후 스토리지 저장이 끝난 후 2번 단계가 수행된다. 이는 수행 윈도우를 증가하게 된다.)</li>\n</ul>\n</li>\n<li>장점으로는 각 단계가 독립적으로 수행되므로 페일오버처리하기가 쉽다.</li>\n</ul>\n</li>\n<li>스트리밍 시스템\n<ul>\n<li>각 단계가 거의 같은 시간에 동작한다. (즉각적으로 전단계에서 발생한 일을 처리하므로)\n<ul>\n<li>따라서, 이벤트가 처리되면 준실시간으로 처리될 수 있다.</li>\n</ul>\n</li>\n<li>단계는 Steaming처럼 Upstream에서 Downstream으로 흐르고, 독립적이지 않기에 페일오버 처리하기가 복잡하다. 따라서, 배치 프로세싱과 달리 실패 시에 별도의 처리가 없다면 핸들링이 어렵다.</li>\n</ul>\n</li>\n</ol>\n<p>위의 내용을 표로 정리하면 아래와 같다.</p>\n<table>\n<thead>\n<tr>\n<th>어플리케이션</th>\n<th>백엔드서비스</th>\n<th>배치 프로세싱</th>\n<th>스트리밍 시스템</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>사용자 인풋에 따라 처리</td>\n<td>요청을 처리</td>\n<td>데이터를 처리</td>\n<td>데이터를 처리</td>\n</tr>\n<tr>\n<td>사용자와 즉각적인 상호작용</td>\n<td>사용자 혹은 다른 서비스와 상호작용</td>\n<td>스케줄 시간 혹은 데이터에 따른 상호작용</td>\n<td>데이터에 따른 상호작용</td>\n</tr>\n<tr>\n<td>사용자에 의한 시작과 끝남</td>\n<td>긴 동작을 하는 프로세스들의 집합</td>\n<td>스케줄 시간에 따른 시작과 끝남</td>\n<td>긴 동작을 하는 단계들의 집합</td>\n</tr>\n<tr>\n<td>싱글 메인 루프</td>\n<td>싱글 메인 루프와 쓰레드들</td>\n<td>여러 단계의 프로세스들</td>\n<td>여러 단계의 프로세스들</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"step-3-간단한-스트리밍-시스템\" style=\"position:relative;\"><a href=\"#step-3-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D-%EC%8B%9C%EC%8A%A4%ED%85%9C\" aria-label=\"step 3 간단한 스트리밍 시스템 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 3. 간단한 스트리밍 시스템</h2>\n<p>이 책에서는 IoT 센서에 대한 예시를 다룬다.\n어떤 다리에 IoT 센서가 있고 트럭인지 버스인지 등을 파악하는 센서가 있다고 가정한다.</p>\n<p>기존 시스템은 백엔드 서비스로 이루어져있었으나 휴일에 많은 트래픽이 몰려서 처리하기 어려운 상황이 놓였었다. 위에서도 설명했듯이 보통의 백엔드 서비스들은 동기적인 처리를 한다.</p>\n<p>즉, 아래와 같이 처리가 된다. 이 경우에는 트래픽이 몰릴 경우 점점 사용자의 응답은 느려질 것이다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/1k3EOQu.png\">\n</p>\n<p align=\"center\">\n<em>그림 12. 동기적 백엔드 서비스 모델, Grokking Streaming Systems : Real-time event Processing, p.66</em>\n</p>\n<p>이 책에서도 동일하게 위에서 설명한 것과 같이 비동기적 처리를 위해서 큐를 도입해서 처리하고자 한다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/c90wSPc.png\">\n</p>\n<p align=\"center\">\n<em>그림 13. 큐를 통한 비동기 처리 도입, Grokking Streaming Systems : Real-time event Processing, p.69</em>\n</p>\n<p>그렇다면, 실제 스트리밍 시스템 내부에는 어떤 원리로 동작을 시키는 지 확인 해보자.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/TdPTbPM.png\">\n</p>\n<p align=\"center\">\n<em>그림 14. 스트리밍 시스템 내부 도식화, Grokking Streaming Systems : Real-time event Processing, p.74</em>\n</p>\n<p>위와 같이 큰 틀로 볼 수 있다.</p>\n<ul>\n<li>Source executor : 이벤트가 발생되는 주체로 볼 수 있으며, 발생된 이벤트들은 큐를 통해서 발송된다.</li>\n<li>Operator executor : 위에서 봤던 전통적인 스트리밍 시스템 구조의 단계에 해당한다고 볼 수 있으며, 이벤트를 알맞게 처리하는 작업을 수행한다.</li>\n</ul>\n<p>이 내용을 좀 더 깊게 들어가면 아래와 같은 그림으로 볼 수 있다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/LmtBDV6.png\">\n</p>\n<p align=\"center\">\n<em>그림 15. 스트리밍 엔진 내부 도식화, Grokking Streaming Systems : Real-time event Processing, p.77</em>\n</p>\n<p>보다 복잡해진 그림을 볼 수 있다. 이를 다시 분해해서 설명하기 위해 아래와 같이 추상화를 해보자.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/ynWz1zz.png\">\n</p>\n<p align=\"center\">\n<em>그림 16. 스트리밍 엔진 내부 도식 추상화, Grokking Streaming Systems : Real-time event Processing, p.78</em>\n</p>\n<p>아주 간단하게 <code class=\"language-text\">Source -> Stream -> Operator</code>의 구조로 추상화를 시킬 수가 있음을 확인할 수 있다.\n여기서 이제 스트리밍 시스템의 5가지 주요 요소를 뽑을 수 있다.</p>\n<ol>\n<li>Job : <code class=\"language-text\">Source -> Stream -> Operator</code> 을 한데 묶은 구조로 다른 말로는 <strong>파이프라인(pipeline)</strong><sup id=\"fnref-10\"><a href=\"#fn-10\" class=\"footnote-ref\">10</a></sup>이라고도 한다. 스트리밍 시스템의 구현체라고 볼 수 있다.</li>\n<li>Source : 외부세계의 데이터를 스트리밍 시스템으로 가져오는 역할을 한다. 이를 <code class=\"language-text\">entry point</code>라고 부르기도 한다.</li>\n<li>Stream : Source에서 전달 받은 이벤트를 Operator에 전달하는 역할을 한다.</li>\n<li>Event : 스트림 내에 더이상 나눌 수 없는 최소 단위의 데이터들을 뜻하며 <code class=\"language-text\">tuple, element, message</code>등등으로도 부르기도 한다.</li>\n<li>Operator : 스트림으로 부터 전달 받은 데이터를 변환하거나 어떠한 로직을 처리하는 역할을 수행한다.</li>\n</ol>\n<p>그림으로 보면 아래와 같다.</p>\n<p align=\"center\">\n    <img src=\"https://i.imgur.com/10c83Zu.png\">\n</p>\n<p align=\"center\">\n<em>그림 17. 스트리밍 시스템 구성요소, Grokking Streaming Systems : Real-time event Processing, p.79</em>\n</p>\n<p>위와 같은 간단한 스트리밍 시스템을 알아보았다.\n글이 길어진 관계로 실제 구현 내용은 아래의 링크로 대체하겠다.</p>\n<ul>\n<li><a href=\"https://github.com/nwangtw/GrokkingStreamingSystems\">Github - nwangtw/GrokkingStreamingSystems</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=A1YC_AC0qf8\">Youtube - Hello Streaming 101</a></li>\n</ul>\n<p>특히, 유튜브 영상은 현재 다뤘던 포스팅의 내용을 전부 다루고 있으니 참고해보길 바란다.\n긴 글 읽어주셔서 감사합니다.</p>\n<h2 id=\"step-4-레퍼런스\" style=\"position:relative;\"><a href=\"#step-4-%EB%A0%88%ED%8D%BC%EB%9F%B0%EC%8A%A4\" aria-label=\"step 4 레퍼런스 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>STEP 4. 레퍼런스</h2>\n<ol>\n<li><a href=\"https://d2.naver.com/helloworld/206816\">Naver D2- 확장성 있는 웹 아키텍처와 분산 시스템</a></li>\n<li><a href=\"https://medium.com/dtevangelist/event-driven-microservice-%EB%9E%80-54b4eaf7cc4a\">Medium - Event Driven Architecture란?</a></li>\n<li><a href=\"https://developer.lightbend.com/docs/akka-guide/concepts/message-driven-event-driven.html\">Lightbend Document -Message Driven vs Event Driven</a></li>\n<li><a href=\"https://stackoverflow.com/questions/1659351/message-driven-vs-event-driven-approaches-to-application-integration\">StackOverflow - message driven vs event driven approaches to application integration</a></li>\n<li><a href=\"https://medium.com/event-driven-utopia/using-commands-events-and-queries-in-microservices-communication-3573f1fcfafe\">Medium - Using Commands, Events, and Queries in Microservices Communication</a></li>\n<li><a href=\"https://bcho.tistory.com/1119\">조대협 - 실시간 빅데이타 처리를 위한 스트리밍 처리의 개념</a></li>\n<li><a href=\"https://medium.com/event-driven-utopia/making-sense-of-unbounded-data-4abdfa0edad2\">Medium -Making Sense of Unbounded Data</a></li>\n</ol>\n<div class=\"footnotes\">\n<hr>\n<ol>\n<li id=\"fn-1\"><a href=\"http://egloos.zum.com/agile/v/3684946\">http://egloos.zum.com/agile/v/3684946</a><a href=\"#fnref-1\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-2\"><a href=\"https://en.wikipedia.org/wiki/Stream_processing\">https://en.wikipedia.org/wiki/Stream_processing</a><a href=\"#fnref-2\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-3\"><a href=\"https://en.wikipedia.org/wiki/Event-driven_architecture\">https://en.wikipedia.org/wiki/Event-driven_architecture</a><a href=\"#fnref-3\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-4\"><a href=\"https://microservices.io/patterns/data/saga.html\">https://microservices.io/patterns/data/saga.html</a><a href=\"#fnref-4\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-5\"><a href=\"https://en.wikipedia.org/wiki/Two-phase_commit_protocol\">https://en.wikipedia.org/wiki/Two-phase_commit_protocol</a><a href=\"#fnref-5\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-6\"><a href=\"https://en.wikipedia.org/wiki/Bottleneck_(network)\">https://en.wikipedia.org/wiki/Bottleneck_(network)</a><a href=\"#fnref-6\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-7\"><a href=\"https://en.wikipedia.org/wiki/Message_broker\">https://en.wikipedia.org/wiki/Message_broker</a><a href=\"#fnref-7\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-8\"><a href=\"https://akka.io/\">https://akka.io/</a><a href=\"#fnref-8\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-9\"><a href=\"https://www.lightbend.com/\">https://www.lightbend.com/</a><a href=\"#fnref-9\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-10\"><a href=\"https://en.wikipedia.org/wiki/Pipeline_(software)\">https://en.wikipedia.org/wiki/Pipeline_(software)</a><a href=\"#fnref-10\" class=\"footnote-backref\">↩</a></li>\n</ol>\n</div>","frontmatter":{"date":"January 09, 2023","title":"스트리밍 시스템 톺아보기","categories":"개발","author":"개발한입","emoji":"💻"},"fields":{"slug":"/overview-streaming-system/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://brewagebear.github.io","comments":{"utterances":{"repo":"brewagebear/blog-comments"}}}}},"pageContext":{"slug":"/fundamental-os-page-cache/","nextSlug":"/overview-streaming-system/","prevSlug":""}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}